{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9fc2842a-f232-4418-b35e-a1857e0347c6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 实验一：比较各个模型的标注效果\n",
    "\n",
    "评测数据集：\n",
    "\n",
    "* TNEWS：新闻标题分类，15个类别\n",
    "\n",
    "对比模型：\n",
    "\n",
    "* ChatGLM2-6B\n",
    "* Qwen-7B-Chat\n",
    "* Siamase-UniNLU-base\n",
    "* paddNLP-zsl分类模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350daade-d134-454e-90d1-284e8a0a225e",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from paddlenlp import Taskflow\n",
    "from modelscope.utils.constant import Tasks\n",
    "from modelscope import Model\n",
    "from modelscope.pipelines import pipeline\n",
    "from modelscope import AutoModelForCausalLM, AutoTokenizer\n",
    "from modelscope import GenerationConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5dc69605-86be-48ea-8492-c3b08a3f7ec2",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-08-23T01:34:50.422595Z",
     "iopub.status.busy": "2023-08-23T01:34:50.422041Z",
     "iopub.status.idle": "2023-08-23T01:34:50.425264Z",
     "shell.execute_reply": "2023-08-23T01:34:50.424825Z",
     "shell.execute_reply.started": "2023-08-23T01:34:50.422571Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 实验设置\n",
    "MODEL_NAME = 'chatglm2-6b' # [chatglm2-6b, qwen-7b-chat, siamese_uninlu, paddle_nlp]\n",
    "DATASET = 'tnews' # [tnews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dbc97633-6032-4f3c-919b-ca6dc008f3c6",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-23T01:37:15.859192Z",
     "iopub.status.busy": "2023-08-23T01:37:15.858867Z",
     "iopub.status.idle": "2023-08-23T01:37:16.052256Z",
     "shell.execute_reply": "2023-08-23T01:37:16.051744Z",
     "shell.execute_reply.started": "2023-08-23T01:37:15.859172Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tnews数据集加载完成!\n",
      "训练集: 53360, 验证集: 5000, 测试集: 5000\n"
     ]
    }
   ],
   "source": [
    "# 读取数据集\n",
    "import json\n",
    "\n",
    "train, val, test = [], [], []\n",
    "\n",
    "if DATASET == 'tnews':\n",
    "    with open('dataset/tnews/train.json', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line.strip())\n",
    "            label = line['label']\n",
    "            text = line['sentence']\n",
    "            train.append([text, label])\n",
    "            \n",
    "    with open('dataset/tnews/dev.json', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line.strip())\n",
    "            label = line['label']\n",
    "            text = line['sentence']\n",
    "            val.append([text, label])\n",
    "            \n",
    "    # 原数据集已随机打散过\n",
    "    test = val[:int(len(val))//2]\n",
    "    val = val[int(len(val)//2):]\n",
    "    \n",
    "    id2en = {}\n",
    "    en2id = {}\n",
    "    \n",
    "    with open('dataset/tnews/labels.json', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line.strip())\n",
    "            id2en[line['label']] = line['label_desc']\n",
    "            en2id[line['label_desc']] = line['label']\n",
    "        \n",
    "    \n",
    "    en2zh = {\n",
    "        'news_story': '故事',\n",
    "        'news_culture': '文化新闻',\n",
    "        'news_entertainment': '娱乐新闻',\n",
    "        'news_sports': '体育新闻',\n",
    "        'news_finance': '经济新闻',\n",
    "        'news_house': '房地产新闻',\n",
    "        'news_car': '汽车新闻',\n",
    "        'news_edu': '教育新闻',\n",
    "        'news_tech': '科技新闻',\n",
    "        'news_military': '军事新闻',\n",
    "        'news_travel': '旅游新闻',\n",
    "        'news_world': '国际新闻',\n",
    "        'news_stock': '股市新闻',\n",
    "        'news_agriculture': '农业新闻',\n",
    "        'news_game': '游戏新闻'\n",
    "    }\n",
    "    \n",
    "    zh2en = {}\n",
    "    for en_name in en2zh:\n",
    "        zh2en[en2zh[en_name]] = en_name\n",
    "        \n",
    "    zh_label_name_list = sorted(list(zh2en.keys()))\n",
    "    en_label_name_list = sorted(list(en2zh.keys()))\n",
    "    \n",
    "    print(f'{DATASET}数据集加载完成!')\n",
    "    print(f'训练集: {len(train)}, 验证集: {len(val)}, 测试集: {len(test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382ae385-3ef7-44c7-8d7d-c05b397e52a3",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 加载模型\n",
    "if MODEL_NAME == 'chatglm2-6b':\n",
    "    model = Model.from_pretrained('ZhipuAI/chatglm2-6b', device_map='auto', revision='v1.0.7')\n",
    "    pipe = pipeline(task=Tasks.chat, model=model)\n",
    "    print('generation_config:', model.generation_config)\n",
    "    print(f'{MODEL_NAME}模型加载完成！')\n",
    "    def get_llm_result(prompt):\n",
    "        inputs = {'text':prompt, 'history': []}\n",
    "        result = pipe(inputs)\n",
    "        return result['response']\n",
    "    \n",
    "elif MODEL_NAME == 'qwen-7b-chat':\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"qwen/Qwen-7B-Chat\", revision = 'v1.0.5',trust_remote_code=True)\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"qwen/Qwen-7B-Chat\", revision = 'v1.0.5',device_map=\"auto\", trust_remote_code=True,fp16 = True).eval()\n",
    "    model.generation_config = GenerationConfig.from_pretrained(\"Qwen/Qwen-7B-Chat\",revision = 'v1.0.5', trust_remote_code=True) # 可指定不同的生成长度、top_p等相关超参\n",
    "    print('generation_config:', model.generation_config)\n",
    "    print(f'{MODEL_NAME}模型加载完成！')\n",
    "    def get_llm_result(prompt):\n",
    "        response, history = model.chat(tokenizer, prompt, history=None)\n",
    "        return response\n",
    "    \n",
    "elif MODEL_NAME == 'siamese_uninlu':\n",
    "    semantic_cls = pipeline(Tasks.siamese_uie, 'damo/nlp_structbert_siamese-uninlu_chinese-base', model_revision='v1.0')\n",
    "    print(f'{MODEL_NAME}模型加载完成！')\n",
    "    if DATASET in ['tnews']:\n",
    "        schema = {'分类': None}\n",
    "    def get_siamase_result(text, label_names):\n",
    "        res = semantic_cls(input=','.join(label_names)+'|'+text, schema = schema)['output']\n",
    "        if len(res) > 0:\n",
    "            return res[0][0]['span']\n",
    "        else:\n",
    "            return ''\n",
    "        \n",
    "elif MODEL_NAME == 'paddle_nlp':\n",
    "    if DATASET in ['tnews', 'nlpcc2014_task2']:\n",
    "        schema = zh_label_name_list\n",
    "        model = Taskflow(\"zero_shot_text_classification\", schema=schema)\n",
    "        print(f'{MODEL_NAME}模型加载完成！')\n",
    "    def get_paddle_result(text):\n",
    "        res = model(text)\n",
    "        if len(res) > 0:\n",
    "            if DATASET in ['tnews', 'nlpcc2014_task2']:\n",
    "                if len(res[0]['predictions']) > 0:\n",
    "                    return res[0]['predictions'][0]['label']\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6191d62-edc2-4037-a9b5-88139b69df12",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-23T01:38:55.148681Z",
     "iopub.status.busy": "2023-08-23T01:38:55.148154Z",
     "iopub.status.idle": "2023-08-23T01:38:55.157444Z",
     "shell.execute_reply": "2023-08-23T01:38:55.156963Z",
     "shell.execute_reply.started": "2023-08-23T01:38:55.148659Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 模型标注方法\n",
    "import re \n",
    "\n",
    "def post_process_llm_cls(llm_out, label_name_list):\n",
    "    # 在分类任务中，对llm out进行后处理，提升coverage\n",
    "    post_process_pat = re.compile(r'(' + r'|'.join(label_name_list) + r')')\n",
    "    # 针对多生成问题\n",
    "    find_names = post_process_pat.findall(llm_out)\n",
    "    if len(find_names) > 0:\n",
    "        # 若有多个结果，默认取第一个\n",
    "        return find_names[0]\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def post_process_siamase_cls(out, label_name_list):\n",
    "    # 在分类任务中，对siamase out进行后处理，提升coverage\n",
    "    for label_name in label_name_list:\n",
    "        if out in label_name:\n",
    "            # 针对片段式抽取问题\n",
    "            return label_name\n",
    "    \n",
    "    return ''\n",
    "\n",
    "\n",
    "def llm_annotator_cls(input_text, label_name_list, few_shot_data = [], self_consistency_num = 1, print_log=False):\n",
    "    if len(few_shot_data) > 0:\n",
    "        example = ''\n",
    "        for d in few_shot_data:\n",
    "            text, label = d[0], d[1]\n",
    "            example += f\"文本:'{text}'\\n\"\n",
    "            example += f'这段文本所属标签：{label}\\n'\n",
    "        \n",
    "        prompt = f'''\n",
    "        给定一段文本，输出一个分类标签。\n",
    "        分类标签集合：[{','.join(label_name_list)}]\n",
    "        请直接输出结果，不要附带其他内容。\n",
    "        \n",
    "        {example}\n",
    "        文本：'{input_text}'\n",
    "        这段文本所属标签：\n",
    "        '''\n",
    "    else:\n",
    "        prompt = f'''\n",
    "        给定一段文本，输出一个分类标签。\n",
    "        分类标签集合：[{','.join(label_name_list)}]\n",
    "        请直接输出结果，不要附带其他内容。\n",
    "        \n",
    "        文本：'{input_text}'\n",
    "        这段文本所属标签：\n",
    "        '''\n",
    "    \n",
    "    result = {}\n",
    "    \n",
    "    for i in range(self_consistency_num):\n",
    "        llm_out = get_llm_result(prompt)\n",
    "        if print_log:\n",
    "            print('prompt:', prompt)\n",
    "            print('llm_out:', llm_out)\n",
    "            \n",
    "        if llm_out not in label_name_list:\n",
    "            # 增加后处理\n",
    "            llm_out = post_process_llm_cls(llm_out, label_name_list)\n",
    "            if print_log:\n",
    "                print('post-process llm_out:', llm_out)\n",
    "        \n",
    "        if llm_out in label_name_list:\n",
    "            if llm_out not in result:\n",
    "                result[llm_out] = 1\n",
    "            else:\n",
    "                result[llm_out] += 1\n",
    "                  \n",
    "    if len(result) > 0:\n",
    "        if print_log:\n",
    "            print('self-consistency result:', result)\n",
    "            print('='*30)\n",
    "            print()\n",
    "        result = sorted(result.items(), key = lambda x: x[1], reverse=True)\n",
    "        return result[0][0]\n",
    "    else:\n",
    "        if print_log:\n",
    "            print('self-consistency result:', result)\n",
    "            print('='*30)\n",
    "            print()\n",
    "        return ''\n",
    "    \n",
    "def siamase_annotator_cls(text, label_name_list, print_log = False):\n",
    "    out = get_siamase_result(text, label_name_list)\n",
    "    if print_log:\n",
    "        print('out:', out)\n",
    "        \n",
    "    if len(out) > 0 and out not in label_name_list:\n",
    "        out = post_process_siamase_cls(out, label_name_list)\n",
    "        if print_log:\n",
    "            print('post-process out:', out)\n",
    "    \n",
    "    if len(out) > 0 and out in label_name_list:\n",
    "        return out\n",
    "    else:\n",
    "        return ''\n",
    "    \n",
    "def paddle_annotator_cls(text, label_name_list, print_log = False):\n",
    "    out = get_paddle_result(text)\n",
    "    if print_log:\n",
    "        print('out:', out)\n",
    "        \n",
    "    if len(out) > 0 and out in label_name_list:\n",
    "        return out\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a253e25-6371-44ed-84de-657fa6cd3d8b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-23T01:39:07.121595Z",
     "iopub.status.busy": "2023-08-23T01:39:07.121277Z",
     "iopub.status.idle": "2023-08-23T01:39:07.127460Z",
     "shell.execute_reply": "2023-08-23T01:39:07.127022Z",
     "shell.execute_reply.started": "2023-08-23T01:39:07.121577Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 标注器\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "# FSL设置\n",
    "use_fsl = False\n",
    "fsl_example_num = 1\n",
    "fsl_example_mode = 'class-balance-fixed' # [random, class-balance-fixed]\n",
    "\n",
    "# Self-Consistency设置\n",
    "self_consistency_num = 1\n",
    "\n",
    "def get_few_shot_example(clean_set, mode = 'random', num = 3):\n",
    "    few_shots = []\n",
    "    \n",
    "    if mode == 'random':\n",
    "        # clean set：[[text, label_name]]\n",
    "        clean_indexs = range(len(clean_set))\n",
    "        few_shot_indexs = np.random.choice(clean_indexs, size = num, replace=False)\n",
    "        for index in few_shot_indexs:\n",
    "            few_shots.append(clean_set[index])\n",
    "        \n",
    "    elif mode == 'class-balance-fixed':\n",
    "        # 按照类别抽，每个class的样本一样，fixed说明不随机抽sample，按顺序抽\n",
    "        # clean set: {'label_name':[text]}\n",
    "        for label_name in sorted(clean_set.keys()):\n",
    "            samples = clean_set[label_name][:num]\n",
    "            for sample in samples:\n",
    "                few_shots.append([sample, label_name])\n",
    "            \n",
    "    return few_shots\n",
    "\n",
    "def annotator(x, zh_label_name_list, use_fsl, clean_pool, fsl_example_mode, fsl_example_num, print_log):\n",
    "    # input：x，output：y（id）\n",
    "    y_pred = ''\n",
    "    if MODEL_NAME in ['chatglm2-6b', 'qwen-7b-chat']:\n",
    "        if use_fsl:\n",
    "            few_shot_examples = get_few_shot_example(clean_pool, mode = fsl_example_mode, num = fsl_example_num)\n",
    "        else:\n",
    "            few_shot_examples = []\n",
    "        out = llm_annotator_cls(x, zh_label_name_list, few_shot_data=few_shot_examples, self_consistency_num = self_consistency_num, print_log = print_log)\n",
    "    elif MODEL_NAME in ['siamese_uninlu']:\n",
    "        out = siamase_annotator_cls(x, zh_label_name_list, print_log=print_log)\n",
    "    elif MODEL_NAME in ['paddle_nlp']:\n",
    "        out = paddle_annotator_cls(x, zh_label_name_list, print_log=print_log)\n",
    "\n",
    "    if len(out) > 0:\n",
    "        if DATASET in ['tnews']:\n",
    "            y_pred = en2id[zh2en[out]]\n",
    "            \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24a4e1c-532e-4db7-9d5d-6b27292c842a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 调参\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# evaluate通用设置\n",
    "do_eval = True\n",
    "runs = 1\n",
    "print_log = False\n",
    "\n",
    "def evaluate(test, clean_pool = []):\n",
    "    y_truth_list, y_pred_list = [], []\n",
    "        \n",
    "    for sample_i in tqdm(range(len(test))):\n",
    "        sample = test[sample_i]\n",
    "        x, y_truth = sample[0], sample[1]\n",
    "        y_pred = annotator(x, zh_label_name_list, use_fsl, clean_pool, fsl_example_mode, fsl_example_num, print_log)\n",
    "            \n",
    "        if len(y_pred) > 0:\n",
    "            y_truth_list.append(y_truth)\n",
    "            y_pred_list.append(y_pred)\n",
    "\n",
    "    accuracy = accuracy_score(np.array(y_truth_list), np.array(y_pred_list))\n",
    "    \n",
    "    print(f'coverage:{len(y_pred_list) / len(test)}')\n",
    "    print(f'accuracy:{accuracy}')\n",
    "\n",
    "# 设置测试集、fsl的clean set来源\n",
    "if do_eval:\n",
    "    if DATASET in ['tnews']:\n",
    "        evaluation_set = train[:100]\n",
    "        if fsl_example_mode == 'random':\n",
    "            clean_pool = []\n",
    "            for d in val[:100]:\n",
    "                clean_pool.append([d[0], en2zh[id2en[d[1]]]])\n",
    "        elif 'class-balance' in fsl_example_mode:\n",
    "            clean_pool = {}\n",
    "            for d in val:\n",
    "                text, label_name = d[0], en2zh[id2en[d[1]]]\n",
    "                if label_name not in clean_pool:\n",
    "                    clean_pool[label_name] = [text]\n",
    "                else:\n",
    "                    clean_pool[label_name].append(text)\n",
    "\n",
    "    for i in range(runs):\n",
    "        evaluate(evaluation_set, clean_pool)\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b2bdfe-8aa9-444c-ba55-e69eb08ed779",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# LLM开启标注 + 映射label\n",
    "label_map = {\n",
    "            100:0,\n",
    "            101:1,\n",
    "            102:2,\n",
    "            103:3,\n",
    "            104:4,\n",
    "            106:5,\n",
    "            107:6,\n",
    "            108:7,\n",
    "            109:8,\n",
    "            110:9,\n",
    "            112:10,\n",
    "            113:11,\n",
    "            114:12,\n",
    "            115:13,\n",
    "            116:14} # 把label_id重新排列，从0开始\n",
    "\n",
    "train_sample = train[:1000]\n",
    "val_sample = val[:1000]\n",
    "test_sample = test[:1000]\n",
    "\n",
    "# 自动标注结果\n",
    "with open(f'/mnt/workspace/exp_dataset/{DATASET}/result_{MODEL_NAME}_{DATASET}_train.json', 'w', encoding='utf-8') as f:\n",
    "    for sample_i in tqdm(range(len(train_sample))):\n",
    "        text, label_id = train_sample[sample_i][0], train_sample[sample_i][1]\n",
    "        llm_annota = annotator(text)\n",
    "        if len(llm_annota) > 0:\n",
    "            f.write(json.dumps({\n",
    "                'sentence': text,\n",
    "                'label': label_map[int(llm_annota)]}, ensure_ascii=False)+'\\n')\n",
    "            \n",
    "with open(f'/mnt/workspace/exp_dataset/{DATASET}/result_{MODEL_NAME}_{DATASET}_val.json', 'w', encoding='utf-8') as f:\n",
    "    for sample_i in tqdm(range(len(val_sample))):\n",
    "        text, label_id = val_sample[sample_i][0], val_sample[sample_i][1]\n",
    "        llm_annota = annotator(text)\n",
    "        if len(llm_annota) > 0:\n",
    "            f.write(json.dumps({\n",
    "                'sentence': text,\n",
    "                'label': label_map[int(llm_annota)]}, ensure_ascii=False)+'\\n')\n",
    "            \n",
    "with open(f'/mnt/workspace/exp_dataset/{DATASET}/result_{MODEL_NAME}_{DATASET}_test.json', 'w', encoding='utf-8') as f:\n",
    "    for sample_i in tqdm(range(len(test_sample))):\n",
    "        text, label_id = test_sample[sample_i][0], test_sample[sample_i][1]\n",
    "        llm_annota = annotator(text)\n",
    "        if len(llm_annota) > 0:\n",
    "            f.write(json.dumps({\n",
    "                'sentence': text,\n",
    "                'label': label_map[int(llm_annota)]}, ensure_ascii=False)+'\\n')\n",
    "            \n",
    "            \n",
    "# 人工标注结果\n",
    "with open(f'/mnt/workspace/exp_dataset/{DATASET}/train.json', 'w', encoding='utf-8') as f:\n",
    "    for sample_i in tqdm(range(len(train_sample))):\n",
    "        text, label_id = train_sample[sample_i][0], train_sample[sample_i][1]\n",
    "        f.write(json.dumps({\n",
    "            'sentence': text,\n",
    "            'label': label_map[int(label_id)]}, ensure_ascii=False)+'\\n')\n",
    "            \n",
    "with open(f'/mnt/workspace/exp_dataset/{DATASET}/val.json', 'w', encoding='utf-8') as f:\n",
    "    for sample_i in tqdm(range(len(val_sample))):\n",
    "        text, label_id = train_sample[sample_i][0], train_sample[sample_i][1]\n",
    "        f.write(json.dumps({\n",
    "            'sentence': text,\n",
    "            'label': label_map[int(label_id)]}, ensure_ascii=False)+'\\n')\n",
    "            \n",
    "with open(f'/mnt/workspace/exp_dataset/{DATASET}/test.json', 'w', encoding='utf-8') as f:\n",
    "    for sample_i in tqdm(range(len(test_sample))):\n",
    "        text, label_id = train_sample[sample_i][0], train_sample[sample_i][1]\n",
    "        f.write(json.dumps({\n",
    "            'sentence': text,\n",
    "            'label': label_map[int(label_id)]}, ensure_ascii=False)+'\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ddb34d-3fd9-4f97-b9a2-70a24456b516",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd25d948-579f-463a-91bd-bf89044f7bed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426514c7-bf02-4906-9cb5-950429d07be7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43fcc1b-6108-48b2-9c20-e9dfb980aa54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
