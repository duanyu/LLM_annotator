{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf0606ad-6752-4f7f-97f2-f2479daab0b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T08:58:33.677763Z",
     "iopub.status.busy": "2023-08-21T08:58:33.677568Z",
     "iopub.status.idle": "2023-08-21T08:58:33.682050Z",
     "shell.execute_reply": "2023-08-21T08:58:33.681096Z",
     "shell.execute_reply.started": "2023-08-21T08:58:33.677744Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 使用Snorkel来ensemble结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "810c06e4-ecff-4706-ba61-3bbf4524d5f2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T08:58:33.683148Z",
     "iopub.status.busy": "2023-08-21T08:58:33.682948Z",
     "iopub.status.idle": "2023-08-21T08:58:35.801252Z",
     "shell.execute_reply": "2023-08-21T08:58:35.800419Z",
     "shell.execute_reply.started": "2023-08-21T08:58:33.683130Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from snorkel.labeling import LabelingFunction\n",
    "from snorkel.labeling import PandasLFApplier\n",
    "from snorkel.labeling import LFAnalysis\n",
    "from snorkel.labeling.model import MajorityLabelVoter, LabelModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a5ed08-3c99-4d04-b606-7ddaa27f510c",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T08:58:35.802996Z",
     "iopub.status.busy": "2023-08-21T08:58:35.802393Z",
     "iopub.status.idle": "2023-08-21T08:58:35.806653Z",
     "shell.execute_reply": "2023-08-21T08:58:35.805975Z",
     "shell.execute_reply.started": "2023-08-21T08:58:35.802972Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ensemble_model = ['chatglm2-6b', 'qwen-7b-chat', 'siamese_uninlu', 'paddle_nlp']\n",
    "DATASET = 'tnews'\n",
    "split = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ad79794-c8cb-4e62-9e26-54229fe764c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T08:58:35.808231Z",
     "iopub.status.busy": "2023-08-21T08:58:35.807915Z",
     "iopub.status.idle": "2023-08-21T08:58:35.812697Z",
     "shell.execute_reply": "2023-08-21T08:58:35.812001Z",
     "shell.execute_reply.started": "2023-08-21T08:58:35.808214Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_anno(dataset, model_name, split='train'):\n",
    "    res = {}\n",
    "    if model_name == 'gt':\n",
    "        fname = f'/mnt/workspace/exp_dataset/{dataset}/{split}.json'\n",
    "    else:\n",
    "        fname = f'/mnt/workspace/exp_dataset/{dataset}/result_{model_name}_{dataset}_{split}.json'\n",
    "    with open(fname, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line.strip())\n",
    "            res[line['sentence']] = line['label']\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a10c71-353c-436c-bf23-45635d2806a0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ABSTAIN = -1\n",
    "\n",
    "def get_acc(gt, pred):\n",
    "    # 考虑覆盖率来计算acc\n",
    "    new_gt, new_pred = [], []\n",
    "    for i in range(len(gt)):\n",
    "        if pred[i] >= 0:\n",
    "            new_gt.append(gt[i])\n",
    "            new_pred.append(pred[i])\n",
    "            \n",
    "    return np.array(new_gt), np.array(new_pred)\n",
    "\n",
    "if DATASET == 'tnews':\n",
    "    texts, labels = [], []\n",
    "    with open(f'/mnt/workspace/exp_dataset/tnews/{split}.json', 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = json.loads(line.strip())\n",
    "            text, label = line['sentence'], line['label']\n",
    "            texts.append(text)\n",
    "            labels.append(label)\n",
    "            \n",
    "    ensemble_model_annota = [get_anno(DATASET, model_name, split=split) for model_name in ensemble_model]\n",
    "    \n",
    "    df = pd.DataFrame()\n",
    "    df['sentence'] = texts\n",
    "    labels = np.array(labels)\n",
    "    \n",
    "    def get_llm_annota(x, model_index):\n",
    "        annota = ensemble_model_annota[model_index]\n",
    "        if x['sentence'] in annota:\n",
    "            return annota[x['sentence']]\n",
    "        else:\n",
    "            return ABSTAIN\n",
    "    \n",
    "    def get_df(model_index):\n",
    "        return LabelingFunction(\n",
    "        name=f\"model_{ensemble_model[model_index]}\",\n",
    "        f=get_llm_annota,\n",
    "        resources=dict(model_index=model_index))\n",
    "    \n",
    "    # 不同的标注结果，构造为不同的LF\n",
    "    LF1 = get_df(0)\n",
    "    LF2 = get_df(1)\n",
    "    LF3 = get_df(2)\n",
    "    LF4 = get_df(3)\n",
    "    \n",
    "    lfs = [LF1, LF2, LF3, LF4]\n",
    "    \n",
    "    applier = PandasLFApplier(lfs=lfs)\n",
    "    L_train = applier.apply(df=df)\n",
    "    \n",
    "    # 应用Label Model，得到estimated label\n",
    "    majority_model = MajorityLabelVoter(cardinality=15)\n",
    "    preds_train_mv = majority_model.predict(L=L_train)\n",
    "    \n",
    "    label_model = LabelModel(cardinality=15, verbose=True)\n",
    "    label_model.fit(L_train=L_train, n_epochs=500, log_freq=100, seed=123)\n",
    "    preds_train_lm = label_model.predict(L=L_train)\n",
    "    \n",
    "    \n",
    "    gt_mv, pred_mv = get_acc(labels, preds_train_mv)\n",
    "    gt_lm, pred_lm = get_acc(labels, preds_train_lm)\n",
    "\n",
    "    print(f'Majority Vote acc（仅衡量覆盖结果): {accuracy_score(gt_mv, pred_mv)}')\n",
    "    print(f'Label Model acc（仅衡量覆盖结果): {accuracy_score(gt_lm, pred_lm)}')\n",
    "    \n",
    "    majority_acc = majority_model.score(L=L_train, Y=labels, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "    print(f\"{'Majority Vote Accuracy:':<25} {majority_acc * 100:.1f}%, coverage:{len([pred for pred in preds_train_mv if pred >= 0]) / len(preds_train_mv)}\")\n",
    "\n",
    "    label_model_acc = label_model.score(L=L_train, Y=labels, tie_break_policy=\"random\")[\"accuracy\"]\n",
    "    print(f\"{'Label Model Accuracy:':<25} {label_model_acc * 100:.1f}%, coverage:{len([pred for pred in preds_train_lm if pred >= 0]) / len(preds_train_lm)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9f2d81-1a2f-4bc9-a6c3-3c1b4074ffa8",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "LFAnalysis(L=L_train, lfs=lfs).lf_summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7990f752-b97e-4d0f-a762-36a1cf100a29",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2023-08-21T08:55:43.407707Z",
     "iopub.status.busy": "2023-08-21T08:55:43.407296Z",
     "iopub.status.idle": "2023-08-21T08:55:43.421411Z",
     "shell.execute_reply": "2023-08-21T08:55:43.420767Z",
     "shell.execute_reply.started": "2023-08-21T08:55:43.407684Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 导出ensemble结果\n",
    "\n",
    "with open(f'/mnt/workspace/exp_dataset/{DATASET}/result_ensemble_MajorityVote_{DATASET}_{split}.json', 'w', encoding='utf-8') as f:\n",
    "    for i in range(len(texts)):\n",
    "        text, label =  texts[i], int(preds_train_lm[i])\n",
    "        if label >= 0:\n",
    "            f.write(json.dumps({\n",
    "                'sentence':text,\n",
    "                'label': label\n",
    "            }, ensure_ascii=False)+'\\n')\n",
    "            \n",
    "with open(f'/mnt/workspace/exp_dataset/{DATASET}/result_ensemble_LabelModel_{DATASET}_{split}.json', 'w', encoding='utf-8') as f:\n",
    "    for i in range(len(texts)):\n",
    "        text, label =  texts[i], int(preds_train_mv[i])\n",
    "        if label >= 0:\n",
    "            f.write(json.dumps({\n",
    "                'sentence':text,\n",
    "                'label': label\n",
    "            }, ensure_ascii=False)+'\\n')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd5f0b3-f8f4-45d7-85d1-ede4079c4b30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a24894-4c4d-4a1b-ac6d-bc50eb930791",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
